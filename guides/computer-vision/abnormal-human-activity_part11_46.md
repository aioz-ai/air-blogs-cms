---  
last_modified_on: "2023-11-13"
title: Abnormal Human Activity Recognition (Part 11 - Overall Summary)
description: A review about Abnormal Human Activity Recognition (the last part).
series_position: 36
author_github: https://github.com/aioz-ai
tags: ["type: insight", "level: easy", "guides: abnormal_activity_recognition"]
---  
# Overral Summary

The existing literature extensively explores the rapid evolution of feature design strategies for video sequences, ranging from manually crafted features to deep learning-based representations. These features play a crucial role in supporting real-time, robust, and computationally efficient frameworks for recognizing abnormal human activities. The context of application varies, including domains such as fall detection, Ambient Assistive Living (AAL), homeland security, surveillance, and crowd analysis. Notably, the choice of feature design methodology adapts to the input dimensions, specifically RGB, depth, and skeleton data.

In recent years, the proliferation of infrared sensors, exemplified by the Microsoft Kinect, has significantly impacted abnormal human activity recognition using depth and skeleton sequences. However, the practical use of Kinect sensors remains confined to specific regions. Consequently, experiments predominantly employ depth sensors alone for fall detection, AAL, and smart home applications related to abnormal human action recognition. Depth and skeleton representations offer valuable view and illumination invariance, addressing critical challenges in crowded or public scenes where dynamic background changes and varying illumination occur in open areas. For scenarios involving multiple individuals and abnormal human activities, RGB images serve as a complementary source of information. Deep feature-based descriptions have outperformed hand-crafted features due to their ability to dynamically learn from video scenes, albeit at the cost of demanding substantial computational resources.

In this study, we systematically investigated publicly available datasets related to fall detection, Ambient Assistive Living (AAL), and abnormal human action recognition. Specifically, we focused on Abnormal Human Activity Recognition (AbHAR) datasets. Among these, several 3D datasets are based on Kinect technology, encompassing pose-based human activity datasets such as MoCap ([Subtle Walking from CMU Mocap Dataset, 2018](https://wangjiangb.github.io/my_data.html)), MHAD ([Teleimmersion Lab, 2018](http://tele-immersion.citris-uc.org/berkeley_mhad)), and the MSRAction3D dataset ([MSR Action 3D Dataset](https://wangjiangb.github.io/my_data.html)). Additionally, various human interaction datasets, including G3Di ([Bloom et al., 2014](https://link.springer.com/chapter/10.1007/978-3-319-16178-5_49)), K3Hi ([K3HI Kinect-based 3D Human Interaction Dataset, 2018](http://www.lmars.whu.edu.cn/prof_web/zhuxinyan/DataSetPublish/dataset.html)), CONVERSE ([Edwards et al., 2016](https://www.sciencedirect.com/science/article/abs/pii/S1077314215002209)), InHOUSE Dataset ([Saini et al., 2017](https://link.springer.com/chapter/10.1007/978-981-10-2104-6_24)), and Fu Kinect Fall Dataset ([Aslan et al., 2017](https://www.researchgate.net/profile/Muzaffer-Aslan/publication/332802502_Skeleton_based_efficient_fall_detection_Eextended_Summarypdf/data/5ccadb7c299bf120978fb6c7/Skeleton-based-efficient-fall-detection-Eextended-Summary.pdf)), have been generated. Notably, while these datasets cover a wide range of activities, only a limited number explicitly address abnormal actions, as identified by previous works ([Nguyen et al., 2016](https://dl.acm.org/doi/10.1145/3011077.3011103); [Khan and Sohn, 2013](https://link.springer.com/article/10.1007/s00607-012-0216-x), [2011](https://ieeexplore.ieee.org/document/6131162); [Han et al., 2016](https://www.sciencedirect.com/science/article/abs/pii/S0925231215008942); [Gasparrini et al., 2015](https://link.springer.com/chapter/10.1007/978-3-319-25733-4_11); [Sucerquia et al., 2017](https://www.mdpi.com/1424-8220/17/1/198)).

In the future, systems for recognizing abnormal human actions must address specific challenges to enable real-time deployment within an affordable range for common users. Such systems play a crucial role in enhancing security in everyday routines.

During our survey, we observed that both handcrafted approaches ([AlNawash et al., 2016](https://link.springer.com/article/10.1007/s00521-016-2363-z); [Roshtkhari and Levine, 2013](https://www.sciencedirect.com/science/article/abs/pii/S1077314213001239); [Wang et al., 2017b](https://link.springer.com/article/10.1007/s11042-015-3199-8); [Uddina et al., 2011](https://journals.sagepub.com/doi/abs/10.1177/1420326X10391140); [Yang et al., 2016](https://www.sciencedirect.com/science/article/pii/S2352864815000681); [Triantafyllou et al., 2016](https://www.sciencedirect.com/science/article/pii/S2405896316324752); [Yu et al., 2013](https://ieeexplore.ieee.org/document/6566012)) and deep feature-based recognition systems ([Li and Chuah, 2018](https://ieeexplore.ieee.org/document/8354150)) struggle to maintain near real-time performance due to the lack of sufficiently large real-time dataset samples for validation. This limitation not only affects system generalizability but also impacts robustness. While human skeletons provide view invariance for action recognition, the availability of abnormal actions from different viewpoints remains a significant challenge. Additionally, existing work ([Diraco et al., 2010](https://ieeexplore.ieee.org/document/5457055)) often relies on artificially generated data, which fails to capture real-life complexities. Therefore, the development of meaningful datasets representing abnormal actions across various scenarios (e.g., office, home, coffee shop) is essential.

Contemporary researchers are actively engaged in advancing deep architectures, ranging from primary Convolutional Neural Networks (CNNs) to more complex models such as Recurrent CNNs (RCNNs), Recurrent Neural Networks (RNNs), and auto-encoders. However, the practical accessibility of efficient and deeper abnormal action recognition systems based on these deep architectures remains a critical concern for the broader user base.

While three-dimensional data has significantly improved the performance of recognition systems, the inherent computational complexity associated with processing such data remains a challenge. Specifically, the transition from three-dimensional data to depth or skeleton-based feature descriptors in real-time Abnormal Human Activity Recognition (AbHAR) systems poses the initial hurdle. Addressing this challenge involves achieving an improved true detection rate while simultaneously minimizing computational demands.

***
*This is the final part of series "Abnormal Human Activity Recognition". Hopefully this useful information will help you better understand this topic.*
***