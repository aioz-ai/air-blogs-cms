---
last_modified_on: "2021-04-09"
id:  vqa-cti
title: Compact Trilinear Interaction for Visual Question Answering
description: "Visual Question Answering."
author_github: https://github.com/Gazeal
tags: ["type: post", "AI", "Computer Vision", "VQA", "Deep Learning"]
---

# Abstract
In Visual Question Answering (VQA), answers greatly correlate with question meaning and visual contents. Thus, to selectively utilize image, question and answer information, we propose a novel trilinear interaction model which simultaneously learns high-level associations between these three inputs. To overcome the interaction complexity, we introduce a multimodal tensor-based PARALIND decomposition that efficiently parameterizes trilinear interaction between the three inputs. Moreover, knowledge distillation is first time applied in Free-form Opened-ended VQA. It is not only for reducing the computational cost and required memory but also for transferring knowledge from the trilinear interaction model to the bilinear interaction model. The extensive experiments on benchmarking datasets TDIUC, VQA-2.0, and Visual7W show that the proposed compact trilinear interaction model achieves state-of-the-art results when using a single model on all three datasets. The source code is available at https://github.com/aioz-ai/ICCV19_VQA-CTI.
